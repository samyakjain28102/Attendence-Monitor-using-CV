{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMO/sTenQuTDBiTYPNDTxTh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TeKLtGrmWvPl"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Model\n","from sklearn import svm\n","import numpy as np"]},{"cell_type":"code","source":["# Load the pre-trained VGG16 model without the top classification layers\n","vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 32, 3))"],"metadata":{"id":"oiA-XgbdX7pu","executionInfo":{"status":"ok","timestamp":1697425234250,"user_tz":-330,"elapsed":1464,"user":{"displayName":"CHAVAN DEEP RAMESH","userId":"13894166060632515917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f8aafce-fb81-40e2-f011-666d00263d25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["base_layers = vgg16_model.layers[:10]\n","\n","# Create a base model containing only the selected layers\n","base_model = Model(inputs=vgg16_model.input, outputs=base_layers[-1].output)\n","\n","print(base_model.summary())"],"metadata":{"id":"NTnMqOXqYX8l","executionInfo":{"status":"ok","timestamp":1697425235370,"user_tz":-330,"elapsed":1131,"user":{"displayName":"CHAVAN DEEP RAMESH","userId":"13894166060632515917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f6ffaac-a5e7-46c6-9c92-abf3d7d87400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 48, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 8, 128)        0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 8, 256)        295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 8, 256)        590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 8, 256)        590080    \n","                                                                 \n","=================================================================\n","Total params: 1735488 (6.62 MB)\n","Trainable params: 1735488 (6.62 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSyxrFtQbawH","executionInfo":{"status":"ok","timestamp":1697425523202,"user_tz":-330,"elapsed":4845,"user":{"displayName":"CHAVAN DEEP RAMESH","userId":"13894166060632515917"}},"outputId":"1b3e388b-6f28-4295-caf3-29d300c3c610"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["for folder_name in os.listdir(root_dir):\n","    folder_path = os.path.join(root_dir, folder_name)\n","\n","    if os.path.isdir(folder_path):\n","        # Get the label from the folder name\n","        label = folder_name\n","\n","        # Iterate through the image files in each subdirectory\n","        for filename in os.listdir(folder_path):\n","            image_path = os.path.join(folder_path, filename)\n","\n","            # Open and load the image using PIL (Pillow)\n","            image = Image.open(image_path)\n","            image = np.array(image)  # Convert to NumPy array if needed\n","\n","            # Append the image and label to the respective lists\n","            images.append(image)\n","            labels.append(label)\n","\n","# Now, 'images' contains the image data, and 'labels' contains the corresponding labels (folder names).\n","In this code:\n","\n","root_dir is set to the path of the root directory where your dataset is stored. This directory should contain subdirectories, and each subdirectory represents a class label.\n","\n","We iterate through the subdirectories in the root directory to extract the labels.\n","\n","For each subdirectory, we iterate through the image files within it, open the images using Pillow, and append them to the images list along with their corresponding labels in the labels list.\n","\n","After running this code, you will have two lists: images containing image data and labels containing the corresponding class labels. You can then use this data for further processing, such as building a machine learning model.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"6v9oJoofbVJc"},"execution_count":null,"outputs":[]}]}